{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: Open Policing Project</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/open-policing-project/\">https://discovery.cs.illinois.edu/microproject/open-policing-project/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: [Stanford Open Policing Project](https://openpolicing.stanford.edu/)\n",
    "\n",
    "The Stanford Open Policing Project is an initiative by the Stanford Computational Journalism Lab to collect, analyze, and provide access to traffic stop data from across the United States.  According to the Open Policing Project, *\"on a typical day in the United States, police officers make more than 50,000 traffic stops\"*. The Open Policing Project aims to provide a comprehensive view of interactions between police officers and the public, focusing on the data collected during traffic stops. It's a crucial resource for understanding issues related to racial profiling, law enforcement tactics, and social justice.\n",
    "\n",
    "The data are collected from state-level and local-level police departments across the country.  As of 2023, project has already collected more than 200 million records from 42 state police departments and growing. The data are collected in a standardized format, and the project provides a [data dictionary](https://openpolicing.stanford.edu/data/) to explain the meaning of each column in the data.\n",
    "\n",
    "This MicroProject will only be looking at the data from the state of Illinois and explore one possible racial disparity among traffic stops in Champaign-Urbana."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting Started: Importing the Necessary Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "To work with the data, we'll need to import pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "To get the data ready for analysis we will first need to do some preprocessing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.1: Read The Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use the `read_csv` function from pandas to read the data from the `illinois_opp.csv.zip`. The data is quite large (the CSV is over 3 GB, over 12 million rows, and 21 columns), and pandas allows us to not need to extract the zip file to load the entire CSV file into memory.\n",
    "\n",
    "Instead we can just use the read_csv function from pandas to read the data directly from the zip file. The `read_csv` function has a `compression` argument which can be set to `zip` to read data directly from a zip file.  For example:\n",
    "> ```\n",
    "> pd.read_csv(\"file.zip\", compression=\"zip\")\n",
    "> ```\n",
    "\n",
    "Use `pd.read_csv` to read `illinois_opp.csv.zip` into a DataFrame called `df`.\n",
    "\n",
    "*(NOTE: Because the data is quite large, it **may take a minute or two to load the data**.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV contains in \"data.zip\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.1: Read The Data\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(\"subject_race\" in df)\n",
    "assert(len(df) == 12748173)\n",
    "assert(df[\"subject_race\"].iloc[30] == \"white\")\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.2: Examine the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Before we start working with the data, lets see what columns are available. Because the data is so large, we don't want to print out the entire DataFrame. Instead we can use the `columns` attribute to get a list of all the columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the columns in `df`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we know what columns are available, lets look at all the unique values in one of the columns. We can use the `unique` method to get a list of all the unique values in a column. Lets look at the unique values in the `department_name` column. The `department_name` column contains the name of the police department that made the traffic stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the all of the unique police departments included in the dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your list of unique values probably doesn't show all the values. This is because there are over 1000 unique values in the `department_name` column. In the next puzzle we will only want to look a some of the departments.  To show all the rows:\n",
    "\n",
    "- Convert the set of unique values to a Python list: `list( df[\"department_name\"].unique() )`\n",
    "- Now, at the bottom, you will see the text:\n",
    "\n",
    "> Output is truncated. View as a <u>scrollable element</u> or open in a <u>text editor</u>. Adjust cell <u>output settings</u>...\n",
    "\n",
    "- Click either \"scrollable element\" or \"text editor\" to then view the entire list without the output being truncated.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the all of the unique police departments included in the dataset, as a Python list:\n",
    "list( df[\"department_name\"].unique() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.3: Keeping Relevant Rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "We currently have the data for the entire state of Illinois. We are only interested in the data from the cities of Champaign and Urbana. We will use the`department_name` column to filter the data. We will want to see if either the word \"Champaign\" **OR** \"Urbana\" appears in the `department_name` column.\n",
    "\n",
    "- Using the `.str.contains` operation on a DataFrame, create a DataFrame called `UIUC_df` that contains only the rows that the `department_name` contains \"Champaign\" or \"Urbana\".\n",
    "- See the DISCOVERY guide [Selecting DataFrame Rows Based on String Contents](https://discovery.cs.illinois.edu/guides/DataFrame-Row-Selection/dataframe-string-contains/) for quick details on how to use `.str.contains`.\n",
    "- Make sure to check the Puzzle 1.2 to notice how the case of the strings need to be to find a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIUC_df = ...\n",
    "UIUC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.3: Keeping Relevant Rows\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"UIUC_df\" in vars())\n",
    "assert(len(UIUC_df) == 102891)\n",
    "assert(UIUC_df[\"subject_race\"].iloc[2000] == \"black\")\n",
    "assert(len(UIUC_df[UIUC_df[\"subject_race\"].str.contains(\"white\")]) == 57830)\n",
    "assert(len(UIUC_df[UIUC_df[\"subject_race\"].str.contains(\"black\")]) == 28700)\n",
    "print(f\"{tada} All Tests Passed! {tada}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Analyzing Racial Disparities among Chambana Traffic Stops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "In Part 2 we will look at how likely it is for different racial groups to be searched during a traffic stop in Champaign-Urbana (or simply \"Chambana\"). \n",
    "\n",
    "In this MicroProject, we're going to specifically explore:\n",
    "- The number of total traffic stops by race,\n",
    "- The number of traffic stops that result in a search taking place by race, and finally\n",
    "- The proportion of all traffic stops that result in a search taking place by race,\n",
    "\n",
    "You can go further and analyze many other things in the dataset as well!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.1: Frequency of Stops per Race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "To find the frequency of stops per race, we will focus on the `subject_race` column in the dataset. This column categorizes each traffic stop by the race of the person who was stopped. Since `UIUC_df` the dataset already contains all the stops in the Chambana area, we can use this column to get a comprehensive view of racial distributions in traffic stops.\n",
    "\n",
    "Using `groupby` (see: [DISCOVERY: Grouping Data in Python](https://discovery.cs.illinois.edu/learn/Exploratory-Data-Analysis/Grouping-Data-in-Python/) for a refresher), group the data by the `subject_race` columns and aggregate the cells together by counting the total number of rows for each `subject_race`.\n",
    "\n",
    "Store this new DataFrame containing the counts of traffic stops by race as `traffic_stops_by_race`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_stops_by_race = ...\n",
    "traffic_stops_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, modify your `traffic_stops_by_race` DataFrame so that it has only two columns: `subject_race` and `stops`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_stops_by_race = ...\n",
    "traffic_stops_by_race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.2: Frequency of Searches per Race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repeat the process again, except now create a DataFrame `traffic_stops_searches_by_race`.\n",
    "\n",
    "- In this new DataFrame, make sure to only include rows from `UIUC_df` where `search_conducted` is `True`.\n",
    "- Then, ensure `traffic_stops_searches_by_race` contains on the columns `subject_race` and `searches`.\n",
    "- Feel free to create extra Python cells here if needed. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_stops_searches_by_race = ...\n",
    "traffic_stops_searches_by_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzles 2.1 and 2.2: Creating Filtered DataFrames\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"race_counts\" in vars())\n",
    "assert(\"search_counts\" in vars())\n",
    "\n",
    "assert(len(traffic_stops_by_race) == 5 and len(traffic_stops_searches_by_race) == 5)\n",
    "\n",
    "assert(\"stops\" in traffic_stops_by_race)\n",
    "assert(\"searches\" in traffic_stops_searches_by_race)\n",
    "assert(\"subject_race\" in traffic_stops_by_race and \"subject_race\" in traffic_stops_searches_by_race)\n",
    "\n",
    "assert(89 in traffic_stops_searches_by_race[\"searches\"].values)\n",
    "assert(228 in traffic_stops_by_race[\"stops\"].values)\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 2.3: Likelihood of Being Searched by Race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we have found the frequency of certain races being stopped and searched we want to find the probability of a person who has been stopped to be searched given their race. More specifcally we want to find:\n",
    "\n",
    "> $ P(searched | RACE = race) $\n",
    "\n",
    "...where race is a race from the `subject_race` column.\n",
    "\n",
    "We will do this by simply dividing the number of people who have been searched by the number of people who have been stopped for each race.  The first thing we need to do is to combine the two DataFrames.\n",
    "\n",
    "- Since our DataFrames `traffic_stops_by_race` and `traffic_stops_searches_by_race` both have a shared column name, we can use `pd.merge` to merge the two DataFrames.\n",
    "- See the [DISCOVERY Guide: Combining DataFrames by Merging](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Merging/) to see the specific syntax.\n",
    "\n",
    "Create a new DataFrame called `df_merged` that merges the two DataFrames into a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = ...\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, create a new column in `df_merged` called `\"P(searched | race)\"` that contains the probability of being searches for each race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = ...\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 2.3: Likelihood of Being Searched by Race\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "import math\n",
    "\n",
    "assert(\"df_merged\" in vars())\n",
    "assert(len(df_merged) == 5)\n",
    "assert(\"P(searched | race)\" in df_merged)\n",
    "assert(\"stops\" in df_merged and \"searches\" in df_merged)\n",
    "assert(math.isclose(df_merged[\"P(searched | race)\"].sum(), 0.22769357713611307))\n",
    "assert(math.isclose(df_merged[\"P(searched | race)\"].std(), 0.038780423471650304))\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: Visualizing the Disparity\n",
    "\n",
    "Using `df_merged.plot.bar(...)`, we can visualize our DataFrame to see the disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.plot.bar(\n",
    "  y=\"P(searched | race)\",\n",
    "  x=\"subject_race\",\n",
    "  title=\"Probability of being searched at a traffic stop in Champaign-Urbana\",\n",
    "  rot=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/open-policing-project/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! 🎉\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
